{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48b9567",
   "metadata": {},
   "source": [
    "# Pre-processing for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a457d49",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdd55a",
   "metadata": {},
   "source": [
    "Import data/packages/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.data_utils import get_feature_lists\n",
    "from src.config import SEED, BASE_PATH\n",
    "from src.preprocess import BMICalculatorArray, transform_export_data, clip_and_round_asa\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    MinMaxScaler,\n",
    "    FunctionTransformer,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df = pd.read_parquet(\n",
    "    BASE_PATH / \"data\" / \"raw\" / \"cleaned\" / \"NSQIP_mast_combined.parquet\"\n",
    ")\n",
    "outcome_df = pd.read_parquet(BASE_PATH / \"data\" / \"processed\" / \"outcome_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7c73c",
   "metadata": {},
   "source": [
    "Reformat outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df686a",
   "metadata": {},
   "source": [
    "Subset DF for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e03c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset\n",
    "keep_cols = [\n",
    "    # Pre-Op\n",
    "    \"AGE\",\n",
    "    \"HEIGHT\",\n",
    "    \"WEIGHT\",\n",
    "    \"SEX\",\n",
    "    \"ETHNICITY_HISPANIC\",  # added\n",
    "    \"RACE\",\n",
    "    \"DIABETES\",\n",
    "    \"HXCOPD\",\n",
    "    \"HXCHF\",\n",
    "    \"ASCITES\",\n",
    "    \"BLEEDDIS\",\n",
    "    \"TRANSFUS\",\n",
    "    \"DIALYSIS\",\n",
    "    \"HYPERMED\",\n",
    "    \"VENTILAT\",\n",
    "    \"SMOKE\",\n",
    "    \"DISCANCR\",\n",
    "    \"RENAFAIL\",\n",
    "    \"STEROID\",\n",
    "    \"ASACLAS\",\n",
    "    \"PRALBUM\",  # added\n",
    "    \"PRWBC\",  # added\n",
    "    \"PRHCT\",  # added\n",
    "    \"PRPLATE\",  # added\n",
    "    \"DYSPNEA\",\n",
    "    \"WNDINF\",\n",
    "    \"WTLOSS\",\n",
    "    # Surgical Characteristics\n",
    "    \"OPTIME\",\n",
    "    \"SURGINDICD\",\n",
    "    \"SNLBCPT\",\n",
    "    \"ALNDCPT\",\n",
    "    \"PARTIALCPT\",\n",
    "    \"SUBSIMPLECPT\",\n",
    "    \"RADICALCPT\",\n",
    "    \"MODIFIEDRADICALCPT\",\n",
    "    \"IMMEDIATECPT\",\n",
    "    \"DELAYEDCPT\",\n",
    "    \"TEINSERTIONCPT\",\n",
    "    \"TEEXPANDERCPT\",\n",
    "    \"FREECPT\",\n",
    "    \"LATCPT\",\n",
    "    \"SINTRAMCPT\",\n",
    "    \"SINTRAMSUPERCPT\",\n",
    "    \"BITRAMCPT\",\n",
    "    \"MASTOCPT\",\n",
    "    \"BREASTREDCPT\",\n",
    "    \"FATGRAFTCPT\",\n",
    "    \"ADJTISTRANSCPT\",\n",
    "    \"AUGPROSIMPCPT\",\n",
    "    \"OTHERRECONTECHCPT\",\n",
    "    \"REVRECBREASTCPT\",\n",
    "    \"NPWTCPT\",\n",
    "    \"URGENCY\",\n",
    "    \"ANESTHES\",\n",
    "    \"SURGSPEC\",\n",
    "    \"INOUT\",\n",
    "    \"OPERYR\",\n",
    "]\n",
    "df_sub = import_df[keep_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccba283",
   "metadata": {},
   "source": [
    "Get feature lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27907b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list_dict = get_feature_lists(df_sub)\n",
    "binary_cols = feat_list_dict[\"binary_cols\"]\n",
    "nominal_cols = feat_list_dict[\"nominal_cols\"]\n",
    "ordinal_cols = feat_list_dict[\"ordinal_cols\"]\n",
    "numerical_cols = feat_list_dict[\"numerical_cols\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596fe19",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fcee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Numerical pipeline #################\n",
    "# ====>Impute, calculate BMI, then scale\n",
    "height_idx = numerical_cols.index(\"HEIGHT\")\n",
    "weight_idx = numerical_cols.index(\"WEIGHT\")\n",
    "# Only age is ~normal --> best to use this over StandardScaler()\n",
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"imputer\",\n",
    "            IterativeImputer(\n",
    "                estimator=None,  # default = BayesianRidge\n",
    "                initial_strategy=\"median\",\n",
    "                max_iter=10,\n",
    "                sample_posterior=False,  # deterministic\n",
    "            ),\n",
    "        ),\n",
    "        (\"bmi\", BMICalculatorArray(height_idx=height_idx, weight_idx=weight_idx)),\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "################# Ordinal pipeline #################\n",
    "# ==============> Separate imputer/encoder for ASA\n",
    "asa_col = [\"ASACLAS\"]\n",
    "# asa_pipeline = Pipeline([(\"encoder\", OrdinalEncoder(categories=[[1, 2, 3, 4]]))])\n",
    "\n",
    "asa_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        # 1. Imputation on the ASA column\n",
    "        (\n",
    "            \"imputer\",\n",
    "            IterativeImputer(\n",
    "                estimator=None,  # default = BayesianRidge\n",
    "                initial_strategy=\"median\",\n",
    "                max_iter=10,\n",
    "                sample_posterior=False,  # deterministic\n",
    "            ),\n",
    "        ),\n",
    "        # 2. Round to nearest integer, cast to int\n",
    "        (\n",
    "            \"round_to_int\",\n",
    "            FunctionTransformer(\n",
    "                clip_and_round_asa,\n",
    "                feature_names_out=\"one-to-one\",\n",
    "            ),\n",
    "        ),\n",
    "        # 3. Ordinal encoding just in case\n",
    "        (\n",
    "            \"encoder\",\n",
    "            OrdinalEncoder(categories=[[1, 2, 3, 4]]),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ==============> Separate encoder for all other ordinals (0, 1, 2+)\n",
    "other_ordinal_cols = [col for col in ordinal_cols if col != \"ASACLAS\"]\n",
    "num_other_ordinal = len(other_ordinal_cols)\n",
    "other_ordinal_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"encoder\",\n",
    "            OrdinalEncoder(\n",
    "                categories=[[\"0\", \"1\", \"2+\"]]\n",
    "                * num_other_ordinal  # Repeat for each column\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "################# Nominal pipeline #################\n",
    "# =========> One-hot encode\n",
    "nom_pipeline = Pipeline([(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "################# Combine all preprocessing #################\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", num_pipeline, numerical_cols),\n",
    "        (\"cat\", nom_pipeline, nominal_cols),\n",
    "        (\"ord_asa\", asa_pipeline, asa_col),\n",
    "        (\"ord_other\", other_ordinal_pipeline, other_ordinal_cols),\n",
    "        (\"bin\", \"passthrough\", binary_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b2b35",
   "metadata": {},
   "source": [
    "Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = BASE_PATH / \"data\" / \"processed\"\n",
    "pipeline_path = BASE_PATH / \"data\" / \"pipelines\"\n",
    "split_outcome_data = {}\n",
    "for outcome_name in outcome_df.columns:\n",
    "    print(f\"{outcome_name}...\")\n",
    "    match outcome_name:\n",
    "        case \"AnyMedComp\":\n",
    "            outcome_name_simplified = \"med_outcome\"\n",
    "        case \"AnySurgComp\":\n",
    "            outcome_name_simplified = \"surg_outcome\"\n",
    "        case \"MORTALITY\":\n",
    "            outcome_name_simplified = \"mort_outcome\"\n",
    "        case \"UNPLREOP\":\n",
    "            outcome_name_simplified = \"reop_outcome\"\n",
    "        case \"VTE\":\n",
    "            outcome_name_simplified = \"vte_outcome\"\n",
    "    split_outcome_data[outcome_name] = transform_export_data(\n",
    "        X=df_sub,\n",
    "        y=outcome_df[outcome_name],\n",
    "        outcome_name=outcome_name_simplified,  # this is only used for dir to write data to\n",
    "        preprocessor=preprocessor,\n",
    "        data_path=data_path,\n",
    "        pipeline_path=pipeline_path,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-breast-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
