import os
import argparse
from pathlib import Path
import time
import optuna
import pandas as pd
import numpy as np
import logging
import json
import torch
from sklearn.model_selection import StratifiedKFold, cross_val_score
from src.config import SEED, NN_TUNE_STAGE
from src.nn_model import TorchNNClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import warnings


################################################################
##################### Train/Prelim Results #####################
################################################################
def train_and_prelim_eval(outcome_name, data_dict, json_path, model_save_path=None):
    """
    Train neural network with best hyperparameters and evaluate on validation set.

    Parameters
    ----------
    outcome_name : str
        Name of the outcome being predicted
    X_train_path : Path
        Path to training features
    y_train_path : Path
        Path to training labels
    params_json_path : Path
        Path to JSON file with best hyperparameters
    """
    X_train = data_dict["X_train"]
    y_train = data_dict["y_train"].values.ravel()
    X_val = data_dict["X_val"]
    y_val = data_dict["y_val"].values.ravel()
    with open(json_path, "r") as f:
        json_params = json.load(f)
    print(f"Training nn for {outcome_name}...")
    print(f"\t Best CV AUROC: \t{json_params["best_score"]:.3f}")
    # ==================================> Extract best param
    best_params = json_params["best_params"]
    # Extract architecture parameters
    hidden_sizes = [best_params["hl_1"], best_params["hl_2"]]
    dropouts = [best_params["dr_1"], best_params["dr_2"]]
    # Add third layer if present
    if "hl_3" in best_params:
        hidden_sizes.append(best_params["hl_3"])
        dropouts.append(best_params["dr_3"])
    # Add fourth layer if present
    if "hl_4" in best_params:
        hidden_sizes.append(best_params["hl_4"])
        dropouts.append(best_params["dr_4"])
    # ============================> Create/fit model
    clf = TorchNNClassifier(
        hidden_size_list=hidden_sizes,
        dropouts=dropouts,
        activation_name="relu",
        lr=best_params["lr"],
        weight_decay=best_params["weight_decay"],
        optimizer_str="adam",
        epochs=80,
        batch_size=16384,
        device="cpu",
        seed=SEED,
        # Early stopping with internal validation
        early_stopping=True,
        es_patience=10,
        es_min_delta=0.0,
        val_split=0.15,  # Internal validation within training
        monitor="auc",
        verbose=1,  # Show progress
    )
    clf.fit(X_train, y_train)
    # ===================================> Evaluate
    y_train_proba = clf.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, y_train_proba)
    y_val_proba = clf.predict_proba(X_val)[:, 1]
    val_auc = roc_auc_score(y_val, y_val_proba)
    ##### Output results #####
    print(f"Train AUROC: \t{train_auc:.3f}")
    print(f"Val ROC AUC: \t{val_auc:.3f}")
    print(f"PARAMS: \t{json_params["best_params"]}")
    print("*" * 10)
    # ==================================> Export
    # Prepare hyperparameters dictionary for saving
    h_params_to_save = {
        "hl_1": best_params["hl_1"],
        "hl_2": best_params["hl_2"],
        "dr_1": best_params["dr_1"],
        "dr_2": best_params["dr_2"],
        "act_func_str": "relu",
        "num_epochs": 80,
        "lr": best_params["lr"],
        "weight_decay": best_params["weight_decay"],
        "batch_size": 16384,
    }
    # Add third layer if present
    if "hl_3" in best_params:
        h_params_to_save["hl_3"] = best_params["hl_3"]
        h_params_to_save["dr_3"] = best_params["dr_3"]

    # Add fourth layer if present (mort_outcome case)
    if "hl_4" in best_params:
        h_params_to_save["hl_4"] = best_params["hl_4"]
        h_params_to_save["dr_4"] = best_params["dr_4"]
    # Create checkpoint dictionary
    checkpoint = {
        "h_params": h_params_to_save,
        "state_dict": clf.model_.state_dict(),  # type: ignore
        "feature_names_in_": clf.feature_names_in_,
    }
    # Save to file
    if model_save_path:
        if model_save_path.exists():
            warnings.warn(f"Over-writing saved model at path {model_save_path}")
            model_save_path.unlink()
        model_save_path.parent.mkdir(exist_ok=True, parents=True)
        torch.save(checkpoint, model_save_path)
        print(f"Model saved to {model_save_path}")


################################################################
######################## Model Builders ########################
################################################################
# ======================================================> STAGE 1
def build_nn_estimator_stage1(trial):
    """
    Model builder used for neural network optuna training (stage 1)
    """
    # 2-3 layers
    n_layers = trial.suggest_int("n_layers", 2, 3)
    ### Hidden Layers ###
    hl_1 = trial.suggest_int("hl_1", 64, 256)
    hl_2 = trial.suggest_int("hl_2", 64, 256)
    h_sizes = [hl_1, hl_2]
    if n_layers == 3:
        hl_3 = trial.suggest_int("hl_3", 32, 256)
        h_sizes.append(hl_3)

    ### Dropouts ###
    # Make relatively wide
    dr_1 = trial.suggest_float("dr_1", 0.0, 0.5)
    dr_2 = trial.suggest_float("dr_2", 0.0, 0.5)
    dropouts = [dr_1, dr_2]
    if n_layers == 3:
        dr_3 = trial.suggest_float("dr_3", 0.0, 0.5)
        dropouts.append(dr_3)

    ####Activation ###
    act_name = trial.suggest_categorical("act_func_str", ["relu", "leaky_relu"])
    ### Epochs ###
    # Keep ~small to get quick signal
    num_epochs = trial.suggest_int("num_epochs", 16, 32)

    ### Optimizer ####
    # opt_choice = trial.suggest_categorical("optimizer", ["adam", "adamw"])
    opt_choice = "adamw"
    lr = trial.suggest_float("lr", 1e-4, 3e-3, log=True)
    wd = trial.suggest_float("weight_decay", 1e-6, 1e-3, log=True)

    ##Batch size
    # can keep ~large bc of GPU
    bs = trial.suggest_categorical("batch_size", [2048, 4096, 8192])

    nn_clf = TorchNNClassifier(
        hidden_size_list=h_sizes,
        dropouts=dropouts,
        activation_name=act_name,
        lr=lr,
        weight_decay=wd,
        epochs=num_epochs,
        batch_size=bs,
        optimizer_str=opt_choice,
        # device=DEVICE, # will set this later right before train time
        seed=SEED,
    )
    return nn_clf


# ======================================================> STAGE 2
def build_nn_estimator_stage2(trial):
    """
    Model builder used for neural network optuna training (stage 2)
    """
    # 2-3 layers
    n_layers = trial.suggest_int("n_layers", 2, 4)
    ### Hidden Layers ###
    hl_1 = trial.suggest_int("hl_1", 128, 512)
    hl_2 = trial.suggest_int("hl_2", 64, 512)
    h_sizes = [hl_1, hl_2]
    if n_layers == 3:
        hl_3 = trial.suggest_int("hl_3", 64, 512)
        h_sizes.append(hl_3)
    if n_layers == 4:
        hl_4 = trial.suggest_int("hl_4", 32, 256)
        h_sizes.append(hl_4)

    ### Dropouts ###
    # Make relatively wide
    dr_1 = trial.suggest_float("dr_1", 0.0, 0.5)
    dr_2 = trial.suggest_float("dr_2", 0.0, 0.5)
    dropouts = [dr_1, dr_2]
    if n_layers == 3:
        dr_3 = trial.suggest_float("dr_3", 0.0, 0.5)
        dropouts.append(dr_3)
    if n_layers == 4:
        dr_4 = trial.suggest_float("dr_4", 0.0, 0.5)
        dropouts.append(dr_4)

    ####Activation ###
    act_name = trial.suggest_categorical("act_func_str", ["relu", "leaky_relu"])
    ### Epochs ###
    # Fix at large number and use early stopping
    num_epochs = 80

    ### Optimizer ####
    opt_choice = trial.suggest_categorical("optimizer", ["adam", "adamw"])
    lr = trial.suggest_float("lr", 1e-4, 1e-2, log=True)
    wd = trial.suggest_float("weight_decay", 1e-6, 1e-3, log=True)

    ##Batch size
    # can keep ~large bc of GPU
    bs = 16384  # keep fixed
    nn_clf = TorchNNClassifier(
        hidden_size_list=h_sizes,
        dropouts=dropouts,
        activation_name=act_name,
        lr=lr,
        weight_decay=wd,
        epochs=num_epochs,
        batch_size=bs,
        optimizer_str=opt_choice,
        seed=SEED,
        ## Early stopping params
        early_stopping=True,
        es_patience=10,  # maybe should tune?
        es_min_delta=0.0,
        val_split=0.2,
        monitor="auc",
    )
    return nn_clf


# ======================================================> STAGE 3
def build_nn_estimator_stage3(trial, outcome: str):
    """
    Model builder for neural network Optuna tuning (stage 3).
    Search space is conditioned on the outcome name.
    """

    if outcome == "mort_outcome":
        # Mortality: 3-4 layers, high dr_1, very low dr_2, fast lr
        n_layers = trial.suggest_int("n_layers", 3, 4)
        hl_1 = trial.suggest_int("hl_1", 340, 480)
        hl_2 = trial.suggest_int("hl_2", 128, 320)
        hl_3 = trial.suggest_int("hl_3", 180, 512)
        h_sizes = [hl_1, hl_2, hl_3]

        dr_1 = trial.suggest_float("dr_1", 0.30, 0.50)
        dr_2 = trial.suggest_float("dr_2", 0.0, 0.20)
        dr_3 = trial.suggest_float("dr_3", 0.0, 0.30)
        dropouts = [dr_1, dr_2, dr_3]

        if n_layers == 4:
            hl_4 = trial.suggest_int("hl_4", 150, 280)
            h_sizes.append(hl_4)
            dr_4 = trial.suggest_float("dr_4", 0.35, 0.50)
            dropouts.append(dr_4)

        lr = trial.suggest_float("lr", 3e-3, 1e-2, log=True)
        wd = trial.suggest_float("weight_decay", 1e-5, 1e-4, log=True)

    elif outcome == "vte_outcome":
        # VTE: 3-4 layers, moderate dropout, wide lr range
        n_layers = trial.suggest_int("n_layers", 3, 4)
        hl_1 = trial.suggest_int("hl_1", 200, 300)
        hl_2 = trial.suggest_int("hl_2", 320, 450)
        hl_3 = trial.suggest_int("hl_3", 300, 512)
        h_sizes = [hl_1, hl_2, hl_3]

        dr_1 = trial.suggest_float("dr_1", 0.18, 0.45)
        dr_2 = trial.suggest_float("dr_2", 0.08, 0.30)
        dr_3 = trial.suggest_float("dr_3", 0.0, 0.20)
        dropouts = [dr_1, dr_2, dr_3]
        if n_layers == 4:
            hl_4 = trial.suggest_int("hl_4", 150, 280)
            h_sizes.append(hl_4)
            dr_4 = trial.suggest_float("dr_4", 0.40, 0.50)
            dropouts.append(dr_4)

        lr = trial.suggest_float("lr", 2e-3, 1e-2, log=True)
        wd = trial.suggest_float("weight_decay", 5e-5, 2e-4, log=True)

    elif outcome == "reop_outcome":
        # Reoperation: 3 layers fixed, LOW dropout (especially dr_2)
        n_layers = 3
        hl_1 = trial.suggest_int("hl_1", 360, 490)
        hl_2 = trial.suggest_int("hl_2", 200, 420)
        hl_3 = trial.suggest_int("hl_3", 180, 512)
        h_sizes = [hl_1, hl_2, hl_3]

        dr_1 = trial.suggest_float("dr_1", 0.05, 0.25)
        dr_2 = trial.suggest_float("dr_2", 0.0, 0.12)
        dr_3 = trial.suggest_float("dr_3", 0.0, 0.18)
        dropouts = [dr_1, dr_2, dr_3]

        lr = trial.suggest_float("lr", 1e-3, 5e-3, log=True)
        wd = trial.suggest_float("weight_decay", 1e-4, 4e-4, log=True)

    elif outcome == "surg_outcome":
        # Surgical: 2 layers fixed, HIGH uniform dropout, smaller net
        n_layers = 2
        hl_1 = trial.suggest_int("hl_1", 150, 280)
        hl_2 = trial.suggest_int("hl_2", 320, 420)
        h_sizes = [hl_1, hl_2]

        dr_1 = trial.suggest_float("dr_1", 0.40, 0.50)
        dr_2 = trial.suggest_float("dr_2", 0.35, 0.50)
        dropouts = [dr_1, dr_2]

        lr = trial.suggest_float("lr", 8e-4, 2e-3, log=True)
        wd = trial.suggest_float("weight_decay", 1e-4, 2e-4, log=True)

    elif outcome == "med_outcome":
        # Medical: 3 layers fixed, wide network, moderate dropout
        n_layers = 3
        hl_1 = trial.suggest_int("hl_1", 400, 512)
        hl_2 = trial.suggest_int("hl_2", 260, 450)
        hl_3 = trial.suggest_int("hl_3", 150, 380)
        h_sizes = [hl_1, hl_2, hl_3]

        dr_1 = trial.suggest_float("dr_1", 0.18, 0.30)
        dr_2 = trial.suggest_float("dr_2", 0.15, 0.30)
        dr_3 = trial.suggest_float("dr_3", 0.05, 0.22)
        dropouts = [dr_1, dr_2, dr_3]

        lr = trial.suggest_float("lr", 8e-4, 2e-3, log=True)
        wd = trial.suggest_float("weight_decay", 1e-4, 3e-4, log=True)

    else:
        raise ValueError(f"Unknown outcome: {outcome}")

    # Fixed across all outcomes (from stage 2 results)
    act_name = "relu"
    opt_choice = "adam"
    num_epochs = 80
    bs = 16384

    nn_clf = TorchNNClassifier(
        hidden_size_list=h_sizes,
        dropouts=dropouts,
        activation_name=act_name,
        lr=lr,
        weight_decay=wd,
        epochs=num_epochs,
        batch_size=bs,
        optimizer_str=opt_choice,
        seed=SEED,
        early_stopping=True,
        es_patience=10,
        es_min_delta=0.0,
        val_split=0.2,
        monitor="auc",
    )
    return nn_clf


################################################################
######################### More Set Up ##########################
################################################################
def build_parser():
    parser = argparse.ArgumentParser(
        prog="Neural Network Tuner",
        description="Tune a neural network with optuna",
    )
    parser.add_argument(
        "--outcome_name", required=True, help="Name of outcome the model will predict"
    )
    parser.add_argument(
        "--X_path", required=True, help="String path to embedding file (X data)"
    )
    parser.add_argument(
        "--y_path",
        required=True,
        help="String path to cleaned raw tabbular data (used to generate y data)",
    )
    parser.add_argument(
        "--gpu_ids_str",
        required=True,
        help='Comma-separated list of GPU IDs (e.g., `"0,1"`, `"4,5,6"`)',
    )
    parser.add_argument(
        "--scoring_str",
        required=True,
        help='Scoring metric used during cross-validation (e.g., `"roc_auc"`)',
    )
    parser.add_argument(
        "--log_path",
        required=True,
        help="Log file path where tuning information for this outcome will be written.",
    )
    parser.add_argument(
        "--results_path",
        required=True,
        help="Output file path where the best score and best trial parameters will be saved in JSON format.",
    )
    parser.add_argument(
        "--n_trials",
        required=True,
        type=int,
        help=f"Number of Optuna trials to run during optimization.",
    )
    parser.add_argument(
        "--seed",
        required=True,
        type=int,
        help=f"Random seed used for Optuna samplers and StratifiedKFold splitting to ensure reproducibility.",
    )
    return parser


def load_data(X_path, y_path, perc):
    """
    Load/subset data from memory

    perc: float
        % of training data to use--> anywhere from (0.0, 1.0]
    """
    X_train = pd.read_parquet(X_path)
    y_train_imp = pd.read_excel(y_path, index_col=0)
    y_train = y_train_imp.values.ravel()
    if perc == 1.0:
        return X_train, y_train
    else:
        X_dummy, X_sub, y_dummy, y_sub = train_test_split(
            X_train, y_train, stratify=y_train, test_size=perc
        )
        return X_sub, y_sub


def parse_arguments(argv=None):
    return build_parser().parse_args(argv)


def main_tuner(
    *_,
    outcome_name,
    X_path,
    y_path,
    gpu_ids_str,
    scoring_str,
    log_path,
    results_path,
    n_trials,
    rand_state,
):
    """
    Tunes a neural network classifier for a single binary outcome using Optuna.
    This function is designed to be called as a standalone tuning worker, typically
    launched in parallel with different GPU assignments. The function loads data,
    configures logging, restricts visible GPUs, constructs a device-aware model
    builder, runs cross-validated optimization, and writes tuning logs and results
    to disk.

    Parameters
    ----------
    outcome_name : str
        Name of the binary outcome variable to tune a model for. Used for logging
        and naming Optuna studies.

    X_path : pathlib.Path
        File path to the predictor matrix used for tuning

    y_path : pathlib.Path
        File path to the outcome data

    gpu_ids_str : str
        Comma-separated list of GPU IDs to expose to this process via the
        `CUDA_VISIBLE_DEVICES` environment variable (e.g., `"0,1"`, `"4,5,6"`).
        Determines which GPUs are available to the model during training.

    scoring_str : str
        Scoring metric used during cross-validation (e.g., `"roc_auc"`). Passed to
        `cross_val_score()`.

    log_path : pathlib.Path
        Log file path where tuning information for this outcome will be written.

    results_path : pathlib.Path
        Output file path where the best score and best trial parameters will be
        saved in JSON format.

    n_trials : int
        Number of Optuna trials to run during optimization.

    rand_state : int
        Random seed used for Optuna samplers and StratifiedKFold splitting to
        ensure reproducibility.

    Returns
    -------
    None
        This function performs tuning, logging, and writing of results to disk.
        It does not return any objects.

    Raises
    ------
    ValueError
        If positional arguments are supplied (this function only accepts keyword
        arguments).

    FileNotFoundError
        If the provided `X_path` or `y_path` does not exist or cannot be loaded by
        `load_data()`.

    RuntimeError
        If CUDA is expected but not available, or if model training fails due to
        GPU configuration or resource errors.

    Notes
    -----
    - The model architecture is constructed inside the objective function using a
      wrapped builder that enforces a specific GPU device.
    - GPU visibility is controlled exclusively by `CUDA_VISIBLE_DEVICES`; within
      this restricted namespace, the classifier uses `"cuda"` automatically.
    - Logging is written incrementally throughout tuning to the designated log file.
    - Each outcome produces one result JSON file containing the best score and
      hyperparameter set.
    """
    if _ != tuple():
        raise ValueError("main_tuner() does not accept positional arguments!")
    # ============ Configure Logger ================
    if log_path.exists():
        log_path.unlink()
    log_path.parent.mkdir(exist_ok=True, parents=True)
    file_handler = logging.FileHandler(log_path, mode="a")
    root_logger = logging.getLogger()
    root_logger.addHandler(file_handler)
    root_logger.setLevel(logging.INFO)
    optuna.logging.enable_propagation()
    optuna.logging.disable_default_handler()
    # ============ Configure Device ================
    os.environ["CUDA_VISIBLE_DEVICES"] = gpu_ids_str
    if torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"
    logging.info(f"Starting tuning for outcome={outcome_name}")
    logging.info(f"CUDA_VISIBLE_DEVICES={gpu_ids_str}, device={device}")

    def build_nn_estimator_for_device(trial):
        """
        Model builder wrapper to set device
        Model created at train time, so setting device after initialization is sufficient
        """
        if NN_TUNE_STAGE == 1:
            nn_clf = build_nn_estimator_stage1(trial)
        elif NN_TUNE_STAGE == 2:
            nn_clf = build_nn_estimator_stage2(trial)
        elif NN_TUNE_STAGE == 3:
            nn_clf = build_nn_estimator_stage3(trial, outcome_name)
        else:
            raise ValueError(
                f"STAGE in src/config.py must be one of [1,2,3]. Got {NN_TUNE_STAGE} instead."
            )
        nn_clf.device = device
        nn_clf.seed = SEED
        return nn_clf

    # ============ Set Up For Tuning ================
    if NN_TUNE_STAGE == 1:
        perc = 0.5
        n_splits = 3
    elif NN_TUNE_STAGE == 2:
        perc = 0.75
        n_splits = 4
    elif NN_TUNE_STAGE == 3:
        perc = 1
        n_splits = 5
    else:
        raise ValueError(
            f"STAGE in src/config.py must be one of [1,2,3]. Got {NN_TUNE_STAGE} instead."
        )
    X_train, y_train = load_data(X_path, y_path, perc)
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rand_state)

    def objective(trial):
        """
        Creates objective for optuna tuning
        """
        start_time = time.perf_counter()
        logging.info(f"Starting trial {trial.number}")
        clf = build_nn_estimator_for_device(trial)
        scores = cross_val_score(
            clf,
            X_train,
            y_train,
            scoring=scoring_str,
            cv=skf,
            n_jobs=1,  # let GPU handle parallelism
        )
        mean_score = float(np.mean(scores))
        # ----- timing + logging end -----
        elapsed = time.perf_counter() - start_time
        logging.info(
            f"Finished trial {trial.number}: "
            f"score={mean_score:.4f}, "
            f"time={elapsed/60:.2f} min"
        )
        logging.info(f"Trial {trial.number}: score={mean_score:.4f}")
        return mean_score

    # ============ Tune ================
    study_name = f"nn_{outcome_name}_study"
    study = optuna.create_study(
        study_name=study_name,
        direction="maximize",
        sampler=optuna.samplers.TPESampler(seed=rand_state),
        pruner=optuna.pruners.HyperbandPruner(min_resource=5, reduction_factor=3),
    )
    logging.info(f"Optuna study created: {study_name}")
    study.optimize(objective, n_trials=n_trials)

    # ====== Deal with results ======
    ## Log results
    logging.info(f"Best {scoring_str}: {study.best_value:.4f}")
    logging.info(f"Best params: {study.best_params}")
    ## Save results
    result = {
        "outcome": outcome_name,
        "best_score": round(study.best_value, 4),
        "best_params": study.best_params,
    }
    ## Each outcome will get its own file
    if results_path.exists():
        results_path.unlink()
    results_path.parent.mkdir(exist_ok=True, parents=True)
    with open(results_path, "w") as f:
        json.dump(result, f, indent=4)

    logging.info(f"Saved best results to {results_path}")

    # ====== Clean up ======
    root_logger.removeHandler(file_handler)
    file_handler.close()


########################################################
######################### Main #########################
########################################################
def main(argv=None):
    ## Parse args
    args = parse_arguments(argv)
    ## Convert str paths to pathlib Paths
    X_path = Path(args.X_path)
    y_path = Path(args.y_path)
    log_path = Path(args.log_path)
    results_path = Path(args.results_path)
    main_tuner(
        outcome_name=args.outcome_name,
        X_path=X_path,
        y_path=y_path,
        gpu_ids_str=args.gpu_ids_str,
        scoring_str=args.scoring_str,
        log_path=log_path,
        results_path=results_path,
        n_trials=args.n_trials,
        rand_state=args.seed,
    )


if __name__ == "__main__":
    main()
